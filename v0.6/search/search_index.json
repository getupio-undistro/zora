{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#what-is-zora","title":"What is Zora?","text":"<p>Zora is a multi-cluster scan that helps you to identify potential issues and vulnerabilities  in your Kubernetes clusters in a centralized way, ensuring that the recommended best practices are in place.</p> <p>Throughout this documentation, we will use the following notation:</p> <ul> <li>Management Cluster to refer to the only Kubernetes cluster where Zora is installed;</li> <li>Target Cluster to refer to all clusters you will connect to Zora to be scanned.</li> </ul> <p>Follow these steps to get started with Zora:</p> <ol> <li> <p>Install Zora in a Management Cluster</p> </li> <li> <p>Prepare the target cluster by creating a service account and generating a kubeconfig</p> </li> <li> <p>Connect the target cluster to Zora</p> </li> <li> <p>Configure a scan for the target cluster</p> </li> <li> <p>After a successful scan checkout the potential reported issues</p> </li> </ol> <p>All the information about these steps are detailed throughout this documentation.</p>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#zora-origins","title":"Zora origins","text":"<p>In the early days of the cloud native era, Borg dominated the container-oriented cluster management scene. The origin of the name Borg refers to the cybernetic life form existing in the Star Trek series,  that worked as a collective of individuals with a single mind and the same purpose, as well as a \"cluster\".</p> <p>As good nerds as we are and wishing to honor our Kubernetes' predecessor (Borg) we named our project Zora.</p> <p>In Star Trek, Zora is the Artificial Intelligence that controls the ship U.S.S Discovery. After being merged with a collective of other intelligences, Zora became sentient and became a member of the team, bringing insights and making the ship more efficient.</p> <p>Like Star Trek's Zora, our goal is to help manage your K8s environment by periodically scanning all of your clusters,  looking for potential issues or vulnerabilities with deployed features and configurations, and helping you ensure compliance with the best practices.</p>"},{"location":"cluster-scan/","title":"Configure a cluster scan","text":"<p>Since your clusters are connected the next and last step is configure a scan for them by creating a <code>ClusterScan</code> in the same namespace as <code>Cluster</code> resource.</p> <p>The <code>ClusterScan</code> will be responsible for reporting issues and vulnerabilities of your clusters.</p> <p>Failure to perform this step implies that the scan will not be performed, and therefore the health of your cluster will be unknown.</p>"},{"location":"cluster-scan/#create-a-clusterscan","title":"Create a <code>ClusterScan</code>","text":"<p>The <code>ClusterScan</code> scans the <code>Cluster</code> referenced in <code>clusterRef.name</code> field periodically on a given schedule,  written in Cron format.</p> <p>Here is a sample configuration that scan <code>mycluster</code> once an hour. You can modify putting your desired periodicity.</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: zora.undistro.io/v1alpha1\nkind: ClusterScan\nmetadata:\nname: mycluster\nnamespace: zora-system\nspec:\nclusterRef:\nname: mycluster\nschedule: \"0 * * * *\"  # at minute 0 past every hour\nEOF\n</code></pre>"},{"location":"cluster-scan/#cron-schedule-syntax","title":"Cron schedule syntax","text":"<p>Cron expression has five fields separated by a space, and each field represents a time unit.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday;\n\u2502 \u2502 \u2502 \u2502 \u2502                                   7 is also Sunday on some systems)\n\u2502 \u2502 \u2502 \u2502 \u2502                                   OR sun, mon, tue, wed, thu, fri, sat\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n</code></pre> Operator Descriptor Example * Any value <code>15 * * * *</code> runs at every minute 15 of every hour of every day. , Value list separator <code>2,10 4,5 * * *</code> runs at minute 2 and 10 of the 4th and 5th hour of every day. - Range of values <code>30 4-6 * * *</code> runs at minute 30 of the 4th, 5th, and 6th hour. / Step values <code>20/15 * * * *</code> runs every 15 minutes starting from minute 20 through 59 (minutes 20, 35, and 50). <p>Now Zora is ready to help you to identify potential issues and vulnerabilities in your kubernetes clusters.</p> <p>You can check the scans status and the reported issues by the following steps:</p>"},{"location":"cluster-scan/#list-cluster-scans","title":"List cluster scans","text":"<p>Listing the <code>ClusterScans</code>, the information of the last scans are available:</p> <p><pre><code>kubectl get clusterscan -o wide\n</code></pre> <pre><code>NAME        CLUSTER     SCHEDULE    SUSPEND   PLUGINS         LAST STATUS   LAST SCHEDULE   LAST SUCCESSFUL   ISSUES   READY   SAAS   AGE   NEXT SCHEDULE\nmycluster   mycluster   0 * * * *   false     marvin,popeye   Complete      13s             1s                34       True    OK     39s   2023-04-18T14:00:00Z\n</code></pre></p> <p>The <code>LAST STATUS</code> column represents the status (<code>Active</code>, <code>Complete</code> or <code>Failed</code>) of the last scan  that was scheduled at the time represented by <code>LAST SCHEDULE</code> column.</p>"},{"location":"cluster-scan/#scanner-plugins","title":"Scanner plugins","text":"<p>Zora uses CLI tools as plugins to scan the clusters.</p> <p>Currently, there are two available plugins:  Marvin and Popeye. Both plugins are used by default in <code>ClusterScans</code>.</p> <p>Info</p> <p>To list the available plugins, run the following command: <pre><code>kubectl get plugins -n zora-system\n</code></pre></p> <p>Marvin is the official Undistro plugin that scans a k8s cluster  by performing CEL (Common Expression Language) expressions.  Similarly, Popeye is a widely used open-source tool for k8s cluster scanning.</p>"},{"location":"cluster-scan/#list-cluster-issues","title":"List cluster issues","text":"<p>Once the cluster is successfully scanned, the reported issues are available in <code>ClusterIssue</code> resources:</p> <p><pre><code>kubectl get clusterissues -l cluster=mycluster\n</code></pre> <pre><code>NAME                              CLUSTER     ID         MESSAGE                                                                             SEVERITY   CATEGORY                  AGE\nmycluster-m-102-18e887d99ccb      mycluster   M-102      Privileged container                                                                High       Security                  100s\nmycluster-m-103-18e887d99ccb      mycluster   M-103      Insecure capabilities                                                               High       Security                  100s\nmycluster-m-104-18e887d99ccb      mycluster   M-104      HostPath volume                                                                     High       Security                  100s\nmycluster-m-105-18e887d99ccb      mycluster   M-105      Not allowed hostPort                                                                High       Security                  100s\nmycluster-m-111-18e887d99ccb      mycluster   M-111      Not allowed volume type                                                             Low        Security                  100s\nmycluster-m-112-18e887d99ccb      mycluster   M-112      Allowed privilege escalation                                                        Medium     Security                  100s\nmycluster-m-113-18e887d99ccb      mycluster   M-113      Container could be running as root user                                             Medium     Security                  100s\nmycluster-m-115-18e887d99ccb      mycluster   M-115      Not allowed seccomp profile                                                         Low        Security                  100s\nmycluster-m-201-18e887d99ccb      mycluster   M-201      Application credentials stored in configuration files                               High       Security                  100s\nmycluster-m-300-18e887d99ccb      mycluster   M-300      Root filesystem write allowed                                                       Low        Security                  100s\nmycluster-pop-102-c6d6b0eefab4    mycluster   POP-102    No probes defined                                                                   Medium     Container                 103s\nmycluster-pop-106-c6d6b0eefab4    mycluster   POP-106    No resources requests/limits defined                                                Medium     Container                 103s\nmycluster-pop-605-c6d6b0eefab4    mycluster   POP-605    If ALL HPAs are triggered, cluster memory capacity will match or exceed threshold   Medium     HorizontalPodAutoscaler   103s\nmycluster-pop-710-c6d6b0eefab4    mycluster   POP-710    Node Memory threshold reached                                                       Medium     Node                      103s\n</code></pre></p> <p>It's possible filter issues by cluster, issue ID, severity and category  using label selector:</p> <pre><code># issues from mycluster\nkubectl get clusterissues -l cluster=mycluster\n\n# clusters with issue POP-106\nkubectl get clusterissues -l id=POP-106\n\n# issues from mycluster with high severity\nkubectl get clusterissues -l cluster=mycluster,severity=High\n\n# only issues reported by the last scan from mycluster\nkubectl get clusterissues -l cluster=mycluster,scanID=fa4e63cc-5236-40f3-aa7f-599e1c83208b\n\n# issues reported from marvin plugin\nkubectl get clusterissues -l plugin=marvin\n\n# issues reported from a custom check\nkubectl get clusterissues -l custom=true\n</code></pre> <p>Why is it an issue?</p> <p>The field <code>url</code> in <code>ClusterIssue</code> spec represents a link for a documentation about this issue. It is displayed in the UI and you can see by <code>kubectl</code> with the <code>-o=yaml</code> flag or the command below.</p> <p><pre><code>kubectl get clusterissues -o=custom-columns=\"NAME:.metadata.name,MESSAGE:.spec.message,URL:.spec.url\"\n</code></pre> <pre><code>NAME                          MESSAGE                                                                        URL\nmycluster-pop-102-27557035    No probes defined                                                              https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\nmycluster-pop-105-27557035    Liveness probe uses a port#, prefer a named port                               &lt;none&gt;\nmycluster-pop-106-27557035    No resources requests/limits defined                                           https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\nmycluster-pop-1100-27557035   No pods match service selector                                                 https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service\nmycluster-pop-306-27557035    Container could be running as root user. Check SecurityContext/Image           https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted\nmycluster-pop-500-27557035    Zero scale detected                                                            https://kubernetes.io/docs/concepts/workloads/\n</code></pre></p> <p>These docs should help you understand why it's an issue and how to fix it.</p> <p>All URLs are available here  and you can contribute to Zora adding new links. See our contribution guidelines.</p>"},{"location":"connect-cluster/","title":"Connect the target cluster to Zora","text":"<p>After preparing your target clusters, you need to connect them directly to Zora by  following the instructions below.</p>"},{"location":"connect-cluster/#prerequisites","title":"Prerequisites","text":"<ol> <li>A kubeconfig file with an authentication <code>token</code> of the target cluster.     Follow these instructions to generate it.</li> <li>The api-server     of the target cluster     must be reachable by the management cluster. </li> </ol> <p>Without the prerequisites Zora will not be able to connect to the target cluster and will set a failure status.</p> <p>Metrics Server</p> <p>If the target cluster hasn't Metrics Server deployed,  information about the usage of memory and CPU won't be collected and issues about potential resources over/under allocations won't be reported.</p> <p>For more information about Metrics Server, visit the official documentation.</p>"},{"location":"connect-cluster/#1-access-the-management-cluster","title":"1. Access the management cluster","text":"<p>First, make sure you are in the context of the management cluster. You can do this by the following commands:</p> <ul> <li> <p>Display list of contexts: <code>kubectl config get-contexts</code></p> </li> <li> <p>Display the current-context: <code>kubectl config current-context</code></p> </li> <li> <p>Set the default context to my-management-cluster: <code>kubectl config use-context my-management-cluster</code></p> </li> </ul>"},{"location":"connect-cluster/#2-create-a-cluster-resource","title":"2. Create a <code>Cluster</code> resource","text":"<p>First, create a <code>Secret</code> with the content of the kubeconfig file:</p> <pre><code>kubectl create secret generic mycluster-kubeconfig \\\n-n zora-system \\\n--from-file=value=zora-view-kubeconfig.yml\n</code></pre> <p>Now, you are able to create a <code>Cluster</code> resource referencing the kubeconfig Secret in the same namespace:</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: zora.undistro.io/v1alpha1\nkind: Cluster\nmetadata:\nname: mycluster\nnamespace: zora-system\nlabels:\nzora.undistro.io/environment: prod\nspec:\nkubeconfigRef:\nname: mycluster-kubeconfig\nEOF\n</code></pre> <p>If you've made it this far, congratulations, your clusters are connected. Now you can list them and see the discovered data through <code>kubectl</code>:</p>"},{"location":"connect-cluster/#list-clusters","title":"List clusters","text":"<p><pre><code>kubectl get clusters -o wide\n</code></pre> <pre><code>NAME        VERSION               MEM AVAILABLE   MEM USAGE (%)   CPU AVAILABLE   CPU USAGE (%)   NODES   READY   AGE   PROVIDER   REGION   \nmycluster   v1.21.5-eks-bc4871b   10033Mi         3226Mi (32%)    5790m           647m (11%)      3       True    40d   aws        us-east-1\n</code></pre></p> <p>Tip</p> <ul> <li>Get clusters from all namespaces using <code>--all-namespaces</code> flag</li> <li>Get clusters with additional information using <code>-o=wide</code> flag</li> <li>Get the documentation for <code>clusters</code> manifests using <code>kubectl explain clusters</code></li> <li>Get cluster from <code>prod</code> environment using <code>kubectl get clusters -l zora.undistro.io/environment=prod</code></li> </ul> <p>The cluster list output has the following columns:</p> <ul> <li><code>NAME</code>: Cluster name</li> <li><code>VERSION</code>: Kubernetes version</li> <li><code>MEM AVAILABLE</code>: Quantity of memory available (requires Metrics Server)</li> <li><code>MEM USAGE (%)</code>: Usage of memory in quantity and percentage (requires Metrics Server)</li> <li><code>CPU AVAILABLE</code>: Quantity of CPU available (requires Metrics Server)</li> <li><code>CPU USAGE (%)</code>: Usage of CPU in quantity and percentage (requires Metrics Server)</li> <li><code>NODES</code>: Total of nodes</li> <li><code>READY</code>: Indicates whether the cluster is connected</li> <li><code>AGE</code>: Age of the kube-system namespace in cluster</li> <li><code>PROVIDER</code>: Cluster provider (with <code>-o=wide</code> flag)</li> <li><code>REGION</code>: Cluster region (<code>multi-region</code> if nodes have different <code>topology.kubernetes.io/region</code> label)   (with <code>-o=wide</code> flag)</li> </ul> <p>Provider</p> <p>The value in <code>PROVIDER</code> column is obtained by matching the Node's labels (e.g., a Node with label key prefix <code>eks.amazonaws.com/</code> means that the provider of this cluster is <code>aws</code>).</p> <p>For now, Zora recognizes only the providers in this list. But you can connect clusters of any provider.  If the provider isn't in this list, the column will not be filled and Zora will continue to work normally.</p> <p>Fell free to contribute to the project and add new labels prefixes for providers.  See our contribution guidelines.</p> <p>Info</p> <ul> <li>The quantity of available and in use resources, is a sum of all Nodes.</li> <li>Only one provider is displayed in <code>PROVIDER</code> column. Different information can be displayed for multi-cloud clusters.</li> <li>Show detailed description of a cluster, including events, running <code>kubectl describe cluster mycluster</code>.</li> </ul>"},{"location":"connect-cluster/#delete-a-cluster","title":"Delete a Cluster","text":"<p>To delete a Cluster, use the following command:</p> <pre><code>kubectl delete cluster mycluster -n zora-system\n</code></pre> <p>This command deletes the <code>mycluster</code> Cluster and its scans and issues.</p> <p>Deleting a Cluster from dashboard (SaaS)</p> <p>If you installed Zora providing a workspace ID (Zora + SaaS) and want to delete your management cluster,  please first delete all target clusters.</p> <p>If you delete the management cluster first,  you will no longer be able to access or delete your target clusters,  which will remain on your dashboard until you contact the Undistro team by email: undistro@getup.io, so that we can proceed with the deletion.</p>"},{"location":"custom-checks/","title":"Custom checks","text":"<p>Zora offers a declarative way to create your own checks using the <code>CustomCheck</code> API, introduced in version 0.6.</p> <p>Custom checks use the Common Expression Language (CEL)  to declare the validation rules and are performed by the Marvin plugin,  so it should be enabled in your cluster scans.</p> <p>Info</p> <p>Marvin is already a default plugin and enabled by default in cluster scans since Zora 0.5.0.</p>"},{"location":"custom-checks/#customcheck","title":"<code>CustomCheck</code>","text":"<p>The example below represents a custom check that requires the labels <code>mycompany.com/squad</code> and <code>mycompany.com/component</code>  to be present on <code>Pods</code>, <code>Deployments</code> and <code>Services</code>.</p> <p>Example</p> <pre><code>apiVersion: zora.undistro.io/v1alpha1\nkind: CustomCheck\nmetadata:\nname: mycheck\nspec:\nmessage: \"Required labels\"\nseverity: Low\ncategory: Custom\nmatch:\nresources:\n- group: \"\"\nversion: v1\nresource: pods\n- group: apps\nversion: v1\nresource: deployments\n- group: \"\"\nversion: v1\nresource: services\nparams:\nrequiredLabels:\n- mycompany.com/squad\n- mycompany.com/component\nvalidations:\n- expression: &gt;\nhas(object.metadata.labels) &amp;&amp;\n!object.metadata.labels.all(label,\nparams.requiredLabels.all(\nreq, req != label\n)\n)\nmessage: \"Resource without required labels\"\n</code></pre> <p>The <code>spec.match.resources</code> defines which resources will be checked by the expressions  defined in <code>spec.validations.expression</code> as Common Expression Language (CEL).</p> <p>If an expression evaluates to <code>false</code>, the check fails and a <code>ClusterIssue</code> is reported.</p>"},{"location":"custom-checks/#variables","title":"Variables","text":"<p>The variables available in CEL expressions:</p> Variable Description <code>object</code> The object being scanned. <code>params</code> The parameter defined in <code>spec.params</code> field. <p>If matches a <code>PodSpec</code>, the following useful variables are available:</p> Variable Description <code>allContainers</code> A list of all containers, including <code>initContainers</code> and <code>ephemeralContainers</code>. <code>podMeta</code> The Pod <code>metadata</code>. <code>podSpec</code> The Pod <code>spec</code>. <p>The following resources matches a <code>PodSpec</code>:</p> <ul> <li><code>v1/pods</code></li> <li><code>v1/replicationcontrollers</code></li> <li><code>apps/v1/replicasets</code></li> <li><code>apps/v1/deployments</code></li> <li><code>apps/v1/statefulsets</code></li> <li><code>apps/v1/daemonsets</code></li> <li><code>batch/v1/jobs</code></li> <li><code>batch/v1/cronjobs</code></li> </ul>"},{"location":"custom-checks/#apply-a-customcheck","title":"Apply a <code>CustomCheck</code>","text":"<p>Since you have a <code>CustomCheck</code> on a file, you can apply it with the command below.</p> <pre><code>kubectl apply -f check.yaml -n zora-system\n</code></pre>"},{"location":"custom-checks/#list-custom-checks","title":"List custom checks","text":"<p>Once created, list the custom checks to see if it's ready.</p> <p><pre><code>kubectl get customchecks -n zora-system\n</code></pre> <pre><code>NAME      MESSAGE           SEVERITY   READY\nmycheck   Required labels   Low        True\n</code></pre></p> <p>The <code>READY</code> column indicates when the check has successfully compiled and is ready to be used in the next Marvin scan.</p> <p><code>ClusterIssues</code> reported by a custom check have are labeled <code>custom=true</code> and can be filtered by the following command:</p> <p><pre><code>kubectl get clusterissues -l custom=true\n</code></pre> <pre><code>NAME                             CLUSTER     ID        MESSAGE           SEVERITY   CATEGORY   AGE\nmycluster-mycheck-4edd75cb85a4   mycluster   mycheck   Required labels   Low        Custom     25s\n</code></pre></p>"},{"location":"custom-checks/#examples","title":"Examples","text":"<p>All Marvin checks are similar to the <code>CustomCheck</code> API.  You can see them in the <code>internal/builtins</code> folder for examples.</p> <p>Some examples of Marvin built-in checks expressions:</p> <ul> <li>HostPath volumes must be forbidden <pre><code>!has(podSpec.volumes) || podSpec.volumes.all(vol, !has(vol.hostPath))\n</code></pre></li> <li>Sharing the host namespaces must be disallowed <pre><code>(!has(podSpec.hostNetwork) || podSpec.hostNetwork == false) &amp;&amp;\n(!has(podSpec.hostPID) || podSpec.hostPID == false) &amp;&amp;\n(!has(podSpec.hostIPC) || podSpec.hostIPC == false)\n</code></pre></li> <li>Privileged Pods disable most security mechanisms and must be disallowed <pre><code>allContainers.all(container,\n  !has(container.securityContext) ||\n  !has(container.securityContext.privileged) ||\n  container.securityContext.privileged == false)\n</code></pre></li> <li>HostPorts should be disallowed entirely (recommended) or restricted to a known list <pre><code>allContainers.all(container,\n  !has(container.ports) ||\n  container.ports.all(port,\n    !has(port.hostPort) ||\n    port.hostPort == 0 ||\n    port.hostPort in params.allowedHostPorts\n  )\n)\n</code></pre></li> </ul> <p>Marvin's checks and Zora's <code>CustomCheck</code> API are inspired in  Kubernetes ValidatingAdmissionPolicy API,  introduced in version 1.26 as an alpha feature.  Below, the table of validation expression examples from Kubernetes documentation.</p> Expression Purpose <code>object.minReplicas &lt;= object.replicas &amp;&amp; object.replicas &lt;= object.maxReplicas</code> Validate that the three fields defining replicas are ordered appropriately <code>'Available' in object.stateCounts</code> Validate that an entry with the 'Available' key exists in a map <code>(size(object.list1) == 0) != (size(object.list2) == 0)</code> Validate that one of two lists is non-empty, but not both <code>!('MY_KEY' in object.map1) || object['MY_KEY'].matches('^[a-zA-Z]*$')</code> Validate the value of a map for a specific key, if it is in the map <code>object.envars.filter(e, e.name == 'MY_ENV').all(e, e.value.matches('^[a-zA-Z]*$')</code> Validate the 'value' field of a listMap entry where key field 'name' is 'MY_ENV' <code>has(object.expired) &amp;&amp; object.created + object.ttl &lt; object.expired</code> Validate that 'expired' date is after a 'create' date plus a 'ttl' duration <code>object.health.startsWith('ok')</code> Validate a 'health' string field has the prefix 'ok' <code>object.widgets.exists(w, w.key == 'x' &amp;&amp; w.foo &lt; 10)</code> Validate that the 'foo' property of a listMap item with a key 'x' is less than 10 <code>type(object) == string ? object == '100%' : object == 1000</code> Validate an int-or-string field for both the int and string cases <code>object.metadata.name.startsWith(object.prefix)</code> Validate that an object's name has the prefix of another field value <code>object.set1.all(e, !(e in object.set2))</code> Validate that two listSets are disjoint <code>size(object.names) == size(object.details) &amp;&amp; object.names.all(n, n in object.details)</code> Validate the 'details' map is keyed by the items in the 'names' listSet <code>size(object.clusters.filter(c, c.name == object.primary)) == 1</code> Validate that the 'primary' property has one and only one occurrence in the 'clusters' listMap"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#management-cluster","title":"Management Cluster","text":"<p>The only Kubernetes cluster where Zora is installed.</p>"},{"location":"glossary/#target-cluster","title":"Target Cluster","text":"<p>The Kubernetes cluster that you connect to Zora to be scanned.</p>"},{"location":"glossary/#cel","title":"CEL","text":"<p>Common Expression Language</p>"},{"location":"helm-chart/","title":"Zora Helm Chart","text":"<p>Zora scans multiple Kubernetes clusters and reports potential issues.</p>"},{"location":"helm-chart/#installing-the-chart","title":"Installing the Chart","text":"<p>To install the chart with the release name <code>zora</code>:</p> <pre><code>helm repo add undistro https://charts.undistro.io --force-update\nhelm upgrade --install zora undistro/zora \\\n  -n zora-system \\\n  --version 0.6.0-rc3 \\\n  --create-namespace --wait\n</code></pre> <p>The Helm chart repository has been updated from <code>https://registry.undistro.io/chartrepo/library</code> to <code>https://charts.undistro.io</code>.</p> <p>The <code>--force-update</code> flag is needed to update the repository URL.</p> <p>These commands deploy Zora on the Kubernetes cluster in the default configuration.</p> <p>The Parameters section lists the parameters that can be configured during installation.</p> <p>Tips:</p> <ul> <li> <p>List all charts available in <code>undistro</code> repo using <code>helm search repo undistro</code></p> </li> <li> <p>Update <code>undistro</code> chart repository using <code>helm repo update undistro</code></p> </li> <li> <p>List all versions available of <code>undistro/zora</code> chart using <code>helm search repo undistro/zora --versions</code></p> </li> <li> <p>List all releases using <code>helm list</code></p> </li> <li> <p>Get the notes provided by <code>zora</code> release using <code>helm get notes zora -n zora-system</code></p> </li> </ul>"},{"location":"helm-chart/#uninstalling-the-chart","title":"Uninstalling the Chart","text":"<p>To uninstall/delete the <code>zora</code> release:</p> <pre><code>$ helm delete zora\n</code></pre> <p>The command removes all the Kubernetes components associated with the chart and deletes the release.</p>"},{"location":"helm-chart/#parameters","title":"Parameters","text":"<p>The following table lists the configurable parameters of the Zora chart and their default values.</p> Key Type Default Description nameOverride string <code>\"\"</code> String to partially override fullname template with a string (will prepend the release name) fullnameOverride string <code>\"\"</code> String to fully override fullname template with a string saas.workspaceID string <code>\"\"</code> Your SaaS workspace ID saas.server string <code>\"https://zora-dashboard.undistro.io\"</code> SaaS server URL saas.hooks.image.repository string <code>\"curlimages/curl\"</code> SaaS hooks image repository saas.hooks.image.tag string <code>\"7.88.1\"</code> SaaS hooks image tag saas.hooks.installURL string <code>\"{{.Values.saas.server}}/zora/api/v1alpha1/workspaces/{{.Values.saas.workspaceID}}/helmreleases\"</code> SaaS install hook URL template imageCredentials.create bool <code>false</code> Specifies whether the secret should be created by providing credentials imageCredentials.registry string <code>\"ghcr.io\"</code> Docker registry host imageCredentials.username string <code>\"\"</code> Docker registry username imageCredentials.password string <code>\"\"</code> Docker registry password imagePullSecrets list <code>[]</code> Specify docker-registry secret names as an array to be used when <code>imageCredentials.create</code> is false operator.replicaCount int <code>1</code> Number of replicas desired of Zora operator operator.image.repository string <code>\"ghcr.io/undistro/zora/operator\"</code> Zora operator image repository operator.image.tag string <code>\"\"</code> Overrides the image tag whose default is the chart appVersion operator.image.pullPolicy string <code>\"IfNotPresent\"</code> Image pull policy operator.rbac.create bool <code>true</code> Specifies whether ClusterRoles and ClusterRoleBindings should be created operator.rbac.serviceAccount.create bool <code>true</code> Specifies whether a service account should be created operator.rbac.serviceAccount.annotations object <code>{}</code> Annotations to be added to service account operator.rbac.serviceAccount.name string <code>\"\"</code> The name of the service account to use. If not set and create is true, a name is generated using the fullname template operator.podAnnotations object <code>{\"kubectl.kubernetes.io/default-container\":\"manager\"}</code> Annotations to be added to pods operator.podSecurityContext object <code>{\"runAsGroup\":65532,\"runAsNonRoot\":true,\"runAsUser\":65532}</code> Security Context to add to the pod operator.securityContext object <code>{\"allowPrivilegeEscalation\":false,\"readOnlyRootFilesystem\":true}</code> Security Context to add to <code>manager</code> container operator.metricsService.type string <code>\"ClusterIP\"</code> Type of metrics service operator.metricsService.port int <code>8443</code> Port of metrics service operator.serviceMonitor.enabled bool <code>false</code> Specifies whether a Prometheus <code>ServiceMonitor</code> should be enabled operator.resources object <code>{\"limits\":{\"cpu\":\"500m\",\"memory\":\"128Mi\"},\"requests\":{\"cpu\":\"10m\",\"memory\":\"64Mi\"}}</code> Resources to add to <code>manager</code> container operator.rbacProxy.image.repository string <code>\"gcr.io/kubebuilder/kube-rbac-proxy\"</code> <code>kube-rbac-proxy</code> image repository operator.rbacProxy.image.tag string <code>\"v0.13.1\"</code> <code>kube-rbac-proxy</code> image tag operator.rbacProxy.image.pullPolicy string <code>\"IfNotPresent\"</code> Image pull policy operator.rbacProxy.securityContext object <code>{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true}</code> Security Context to add to <code>kube-rbac-proxy</code> container operator.rbacProxy.resources object <code>{\"limits\":{\"cpu\":\"500m\",\"memory\":\"128Mi\"},\"requests\":{\"cpu\":\"5m\",\"memory\":\"64Mi\"}}</code> Resources to add to <code>kube-rbac-proxy</code> container operator.nodeSelector object <code>{}</code> Node selection to constrain a Pod to only be able to run on particular Node(s) operator.tolerations list <code>[]</code> Tolerations for pod assignment operator.affinity object <code>{}</code> Map of node/pod affinities operator.log.encoding string <code>\"json\"</code> Log encoding (one of 'json' or 'console') operator.log.level string <code>\"info\"</code> Log level to configure the verbosity of logging. Can be one of 'debug', 'info', 'error', or any integer value &gt; 0 which corresponds to custom debug levels of increasing verbosity operator.log.stacktraceLevel string <code>\"error\"</code> Log level at and above which stacktraces are captured (one of 'info', 'error' or 'panic') operator.log.timeEncoding string <code>\"rfc3339\"</code> Log time encoding (one of 'epoch', 'millis', 'nano', 'iso8601', 'rfc3339' or 'rfc3339nano') scan.worker.image.repository string <code>\"ghcr.io/undistro/zora/worker\"</code> worker image repository scan.worker.image.tag string <code>\"\"</code> Overrides the image tag whose default is the chart appVersion scan.defaultPlugins list <code>[\"popeye\",\"marvin\"]</code> Names of the default plugins scan.plugins.marvin.enabled bool <code>true</code> Specifies whether the marvin plugin should be created scan.plugins.marvin.resources object <code>{\"limits\":{\"cpu\":\"500m\",\"memory\":\"500Mi\"},\"requests\":{\"cpu\":\"250m\",\"memory\":\"256Mi\"}}</code> Resources to add to <code>marvin</code> container scan.plugins.marvin.image.repository string <code>\"ghcr.io/undistro/marvin\"</code> marvin plugin image repository scan.plugins.marvin.image.tag string <code>\"v0.1.6\"</code> marvin plugin image tag scan.plugins.popeye.enabled bool <code>true</code> Specifies whether the popeye plugin should be created scan.plugins.popeye.skipInternalResources bool <code>false</code> Specifies whether the following resources should be skipped by <code>popeye</code> scans. 1. resources from <code>kube-system</code>, <code>kube-public</code> and <code>kube-node-lease</code> namespaces; 2. kubernetes system reserved RBAC (prefixed with <code>system:</code>); 3. <code>kube-root-ca.crt</code> configmaps; 4. <code>default</code> namespace; 5. <code>default</code> serviceaccounts; 6. Helm secrets (prefixed with <code>sh.helm.release</code>); 7. Zora components. See <code>popeye</code> configuration file that is used for this case: https://github.com/undistro/zora/blob/main/charts/zora/templates/plugins/popeye-config.yaml scan.plugins.popeye.resources object <code>{\"limits\":{\"cpu\":\"500m\",\"memory\":\"500Mi\"},\"requests\":{\"cpu\":\"250m\",\"memory\":\"256Mi\"}}</code> Resources to add to <code>popeye</code> container scan.plugins.popeye.image.repository string <code>\"ghcr.io/undistro/popeye\"</code> popeye plugin image repository scan.plugins.popeye.image.tag string <code>\"pr252\"</code> popeye plugin image tag kubexnsImage.repository string <code>\"ghcr.io/undistro/kubexns\"</code> kubexns image repository kubexnsImage.tag string <code>\"v0.1.1\"</code> kubexns image tag customChecksConfigMap string <code>\"zora-custom-checks\"</code> Custom checks ConfigMap name <p>Specify each parameter using the <code>--set key=value[,key=value]</code> argument to <code>helm install</code>. For example,</p> <pre><code>$ helm install zora \\\n--set server.service.port=8080 undistro/zora\n</code></pre> <p>Alternatively, a YAML file that specifies the values for the parameters can be provided while installing the chart. For example,</p> <pre><code>$ helm install zora -f values.yaml undistro/zora\n</code></pre> <p>Tip: You can use the default values.yaml</p>"},{"location":"install/","title":"Install","text":"<p>Zora requires an existing Kubernetes cluster accessible via <code>kubectl</code>. After the installation process this cluster will be your management cluster with the Zora components installed.  So it is recommended to keep it separated from any application workload.</p>"},{"location":"install/#setup-requirements","title":"Setup Requirements","text":"<p>Zora's management cluster requires these programs in order to be installed and configured:</p> <ul> <li>Kubernetes &gt;= 1.21.0</li> <li>Helm &gt;= 3.4.0</li> <li>Kubectl</li> <li>Awk</li> <li>Cat</li> <li>POSIX shell</li> </ul>"},{"location":"install/#install-with-helm","title":"Install with Helm","text":"<p>Migrating to version 0.6</p> <p>If you already have Zora installed and want to migrate to zora 0.6,  you need to follow some additional steps.</p> <p>Before running the <code>helm upgrade</code> command, it is necessary to apply the modified CRDs. <pre><code>kubectl apply -f https://raw.githubusercontent.com/undistro/zora/v0.6.0-rc3/charts/zora/crds/zora.undistro.io_clusterissues.yaml\nkubectl apply -f https://raw.githubusercontent.com/undistro/zora/v0.6.0-rc3/charts/zora/crds/zora.undistro.io_customchecks.yaml\nkubectl apply -f https://raw.githubusercontent.com/undistro/zora/v0.6.0-rc3/charts/zora/crds/zora.undistro.io_plugins.yaml\n</code></pre> These commands ensure that the modified Custom Resource Definitions (CRDs) are applied correctly.</p> <p>By default, Helm does not upgrade CRDs automatically, which is why this manual step is necessary.</p> <ol> <li>To install Zora using Helm follow these commands:</li> </ol> Zora + SaaSZora (kubectl) <p>In this option you have access to the powerful dashboard to see your clusters and issues.</p> <p>Warning</p> <p>The SaaS (<code>https://zora-dashboard.undistro.io/</code>) must be reachable by Zora.</p> <p>1.1 Sign in at https://zora-dashboard.undistro.io/ and select a workspace</p> <p>1.2 Get your workspace ID by clicking on  and provide it by the <code>saas.workspaceID</code> flag:</p> <pre><code>helm repo add undistro https://charts.undistro.io --force-update\nhelm repo update undistro\nhelm upgrade --install zora undistro/zora \\\n--set saas.workspaceID='&lt;YOUR WORKSPACE ID&gt;'\n-n zora-system \\\n--version 0.6.0-rc3 \\\n--create-namespace --wait\n</code></pre> <p>In this option you can see your clusters and issues by <code>kubectl</code>.</p> <pre><code>helm repo add undistro https://charts.undistro.io --force-update\nhelm repo update undistro\nhelm upgrade --install zora undistro/zora \\\n-n zora-system \\\n--version 0.6.0-rc3 \\\n--create-namespace --wait\n</code></pre> <p>Info</p> <p>The Helm chart repository has been updated from <code>https://registry.undistro.io/chartrepo/library</code> to <code>https://charts.undistro.io</code>.</p> <p>The <code>--force-update</code> flag is needed to update the repository URL.</p> <p>These commands deploy Zora to the Kubernetes cluster. This section lists the parameters that can be configured during installation.</p>"},{"location":"install/#access-to-the-dashboard","title":"Access to the dashboard","text":"<p>If you installed Zora providing a workspace ID (Zora + SaaS),  you have access to the powerful dashboard at https://zora-dashboard.undistro.io/</p> <p>The output of <code>helm install</code> and <code>helm upgrade</code> commands contains the dashboard URL and you can get it anytime by running: </p> <pre><code>helm get notes zora -n zora-system\n</code></pre>"},{"location":"install/#uninstall","title":"Uninstall","text":"<pre><code>helm delete zora -n zora-system\nkubectl delete namespace zora-system\n</code></pre>"},{"location":"target-cluster/","title":"Prepare the target cluster","text":"<p>Follow this guide to create a service account and generate a kubeconfig file from a target cluster. These are the only steps required to be performed in the target cluster.</p> <p>For manual configuration, go to Manual Configuration, otherwise proceed to Setup Script.</p> <p>Note</p> <p>If your target cluster is under a server proxy for external communication, like those present on platforms like Rancher,  we recommend generating a kubeconfig file through your own platform.</p> <p>Normally these platforms handle their own tokens instead of a service account token.</p> <p>Zora requires read-only access, as described here.</p>"},{"location":"target-cluster/#setup-script","title":"Setup Script","text":"<p>A script is available to prepare a cluster, which can be executed by any POSIX compliant shell. </p> <pre><code>curl -q https://zora-docs.undistro.io/v0.5/targetcluster.sh | sh\n</code></pre> <p>By default, the script uses the current context.  But it's possible to set the target cluster context by exporting the  <code>CONTEXT</code>:</p> <pre><code>curl -q https://zora-docs.undistro.io/v0.5/targetcluster.sh | CONTEXT=&lt;TARGET_CONTEXT&gt; sh\n</code></pre> <p>Or switching the current context via <code>kubectl</code> before running the script:</p> <pre><code>kubectl config use-context &lt;TARGET_CONTEXT&gt;\ncurl -q https://zora-docs.undistro.io/v0.5/targetcluster.sh | sh\n</code></pre> <p>The generated kubeconfig will be named as your Kuberntes context suffixed with <code>-kubeconfig.yaml</code>, by default.</p> <p>Before finishing, the script will show a command to connect the target cluster through the generated kubeconfig, and save a sample <code>Cluster</code> manifest.</p> <p>A complete list of customizable environment variables can be seen on the table below.</p> Environment Variable Description <code>SVC_ACCOUNT_NS</code> Service Account namespace, defaults to <code>zora-system</code> <code>SVC_ACCOUNT_NAME</code> Service Account name, defaults to <code>zora-view</code> <code>CLUSTER_ROLE_NAME</code> Cluster Role name, defaults to <code>zora-view</code> <code>SVC_ACCOUNT_SECRET_NS</code> Service Account Secret namespace, defaults to the value of <code>SVC_ACCOUNT_NS</code> <code>SVC_ACCOUNT_SECRET_NAME</code> Service Account Secret name, defaults to the of value of <code>SVC_ACCOUNT_NAME</code> with the \"-token\" suffix <code>KCONFIG_SECRET_NAME</code> Name of the displayed kubeconfig Secret, defaults to the value of <code>CLUSTER_NAME</code> with the \"-kubeconfig\" suffix <code>TOKEN_NAME</code> Uses the value of <code>SVC_ACCOUNT_SECRET_NAME</code> or the one generated by K8s, according to the cluster version <code>CONTEXT</code> K8s context, using the current one as default <code>CLUSTER_NAME</code> Cluster name from the <code>CONTEXT</code> variable <code>CLUSTER_NS</code> Cluster namespace used on the manifest sample, defaults to the value of <code>SVC_ACCOUNT_NS</code> <code>CLUSTER_CA</code> Cluster Certificate Authority, extracted according to <code>CONTEXT</code> <code>CLUSTER_SERVER</code> Cluster server address, extracted according to <code>CONTEXT</code> <code>KCONFIG_NAME</code> Name of the generated kubeconfig, defaulting to the value of <code>CONTEXT</code> plus the string \"_kubeconfig.yaml\" <code>SAMPLE_MANIFEST_NAME</code> Name of the <code>Cluster</code> manifest sample, defaults to <code>cluster_sample.yaml</code> plus the K8s context as prefix <p>The next instructions explain how to manually configure your target clusters.</p>"},{"location":"target-cluster/#manual-configuration","title":"Manual Configuration","text":"<p>The target cluster can be configured through the steps described in the next sections.</p>"},{"location":"target-cluster/#1-access-the-target-cluster","title":"1. Access the target cluster","text":"<p>First, make sure you are in the context of the target cluster. You can do this by the following commands:</p> <ul> <li> <p>Display list of contexts: <code>kubectl config get-contexts</code></p> </li> <li> <p>Display the current-context: <code>kubectl config current-context</code></p> </li> <li> <p>Set the default context to my-target-cluster: <code>kubectl config use-context my-target-cluster</code></p> </li> </ul>"},{"location":"target-cluster/#2-create-the-rbac-resources","title":"2. Create the RBAC resources","text":"<p>Create the service account in a separate namespace and configure <code>view</code> permissions. The token generated by this service account will be used in the kubeconfig file.</p> <p>Important</p> <p>You should create a separate service account in the target cluster to connect it to Zora.  This is required because the kubeconfig files generated by most cloud providers,  call CLI commands, such as <code>aws</code> or <code>gcloud</code>, those can\u2019t be called by Zora.</p> <pre><code>kubectl create namespace zora-system\nkubectl -n zora-system create serviceaccount zora-view\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\nname: zora-view\nrules:\n- apiGroups: [ \"\" ]\nresources:\n- configmaps\n- endpoints\n- limitranges\n- namespaces\n- nodes\n- persistentvolumes\n- persistentvolumeclaims\n- pods\n- replicationcontrollers\n- secrets\n- serviceaccounts\n- services\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ \"apps\" ]\nresources:\n- daemonsets\n- deployments\n- statefulsets\n- replicasets\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ \"autoscaling\" ]\nresources:\n- horizontalpodautoscalers\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ \"networking.k8s.io\" ]\nresources:\n- ingresses\n- networkpolicies\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ \"policy\" ]\nresources:\n- poddisruptionbudgets\n- podsecuritypolicies\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ \"rbac.authorization.k8s.io\" ]\nresources:\n- clusterroles\n- clusterrolebindings\n- roles\n- rolebindings\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ \"metrics.k8s.io\" ]\nresources:\n- pods\n- nodes\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ batch ]\nresources:\n- jobs\n- cronjobs\nverbs: [ \"get\", \"list\" ]\n- apiGroups: [ admissionregistration.k8s.io ]\nresources:\n- validatingwebhookconfigurations\n- mutatingwebhookconfigurations\nverbs: [ \"get\", \"list\" ]\nEOF\nkubectl create clusterrolebinding zora-view --clusterrole=zora-view --serviceaccount=zora-system:zora-view\n</code></pre> <p>Info</p> <p>Zora requires just view permissions of your target clusters.</p>"},{"location":"target-cluster/#3-set-up-the-environment-variables","title":"3. Set up the environment variables","text":"<p>Set up the following environment variables based on the Kubernetes version of the target cluster.</p> <p>You can verify the version of your cluster by running: <pre><code>kubectl version\n</code></pre></p> <p>The Server Version is the version of Kubernetes your target cluster is running.</p> Kubernetes prior to 1.24.0Kubernetes 1.24.0 or later <pre><code>export TOKEN_NAME=$(kubectl -n zora-system get serviceaccount zora-view -o=jsonpath='{.secrets[0].name}')\nexport TOKEN_VALUE=$(kubectl -n zora-system get secret ${TOKEN_NAME} -o=jsonpath='{.data.token}' | base64 --decode)\nexport CURRENT_CONTEXT=$(kubectl config current-context)\nexport CURRENT_CLUSTER=$(kubectl config view --raw -o=go-template='{{range .contexts}}{{if eq .name \"'''${CURRENT_CONTEXT}'''\"}}{{ index .context \"cluster\" }}{{end}}{{end}}')\nexport CLUSTER_CA=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}\"{{with index .cluster \"certificate-authority-data\" }}{{.}}{{end}}\"{{ end }}{{ end }}')\nexport CLUSTER_SERVER=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}{{ .cluster.server }}{{end}}{{ end }}')\n</code></pre> <pre><code>export TOKEN_NAME=\"zora-view-token\"\ncat &lt;&lt; EOF | kubectl apply -f - \napiVersion: v1\nkind: Secret\nmetadata:\n    name: \"$TOKEN_NAME\"\n    namespace: \"zora-system\"\n    annotations:\n        kubernetes.io/service-account.name: \"zora-view\"\ntype: kubernetes.io/service-account-token\nEOF\nexport TOKEN_VALUE=$(kubectl -n zora-system get secret ${TOKEN_NAME} -o=jsonpath='{.data.token}' | base64 --decode)\nexport CURRENT_CONTEXT=$(kubectl config current-context)\nexport CURRENT_CLUSTER=$(kubectl config view --raw -o=go-template='{{range .contexts}}{{if eq .name \"'''${CURRENT_CONTEXT}'''\"}}{{ index .context \"cluster\" }}{{end}}{{end}}')\nexport CLUSTER_CA=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}\"{{with index .cluster \"certificate-authority-data\" }}{{.}}{{end}}\"{{ end }}{{ end }}')\nexport CLUSTER_SERVER=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}{{ .cluster.server }}{{end}}{{ end }}')\n</code></pre>"},{"location":"target-cluster/#4-generate-a-kubeconfig-file","title":"4. Generate a kubeconfig file","text":"<p>Generate a file with kubeconfig data, based on the environment variables defined before:</p> <pre><code>cat &lt;&lt; EOF &gt; zora-view-kubeconfig.yml\napiVersion: v1\nkind: Config\ncurrent-context: ${CURRENT_CONTEXT}\ncontexts:\n- name: ${CURRENT_CONTEXT}\ncontext:\ncluster: ${CURRENT_CONTEXT}\nuser: zora-view\nclusters:\n- name: ${CURRENT_CONTEXT}\ncluster:\ncertificate-authority-data: ${CLUSTER_CA}\nserver: ${CLUSTER_SERVER}\nusers:\n- name: zora-view\nuser:\ntoken: ${TOKEN_VALUE}\nEOF\n</code></pre> Example of a generated kubeconfig file <pre><code>apiVersion: v1\nkind: Config\ncurrent-context: mycluster-prod\ncontexts:\n- name: mycluster-prod\ncontext:\ncluster: mycluster-prod\nuser: zora-view\nclusters:\n- name: mycluster-prod\ncluster:\ncertificate-authority-data: LS0tLS1CRUdJTiBDRVJU...OMITTED\nserver: https://OMITTED.us-east-1.eks.amazonaws.com\nusers:\n- name: zora-view\nuser:\ntoken: eyJhbGciOiJSUzI1NiIs...OMITTED\n</code></pre>"},{"location":"target-cluster/#verify-the-generated-kubeconfig","title":"Verify the generated kubeconfig","text":"<p>These steps create a file in your current working directory called <code>zora-view-kubeconfig.yml</code>. The contents of this file are used in the next guide to connect this target cluster into Zora.</p> <p>Before using this kubeconfig, you can verify that it is functional by running:</p> <pre><code>kubectl --kubeconfig zora-view-kubeconfig.yml get all --all-namespaces\n</code></pre>"}]}